# GenAI Text Summarization Project

## ğŸ“ Project Description

This project demonstrates both **Abstractive** and **Extractive** text summarization techniques using state-of-the-art transformer models. Built using Python and Hugging Face Transformers, the goal is to provide concise summaries of longer textual content for applications like content generation, article compression, or information retrieval.

It supports:  
- **Abstractive Summarization** using `facebook/bart-large-cnn`, which generates human-like summaries.  
- **Extractive Summarization** using the `sentence-transformers/all-MiniLM-L6-v2` model and cosine similarity, which selects the most important sentences from the text.

---

## ğŸ§  Features

- ğŸ” Dual approach: **Abstractive + Extractive** summarization  
- âš¡ Built on top of **Hugging Face Transformers** and **PyTorch**  
- ğŸ§ª Handles small to moderately large text inputs effectively  
- ğŸŒ Scalable to web or app deployment via Streamlit or Flask  
- ğŸ§  Utilizes sentence embeddings and cosine similarity for extractive summaries
- ğŸ—ƒï¸ Document uploads (PDFs, .txt) for summarization

---

## ğŸ§° Libraries and Tech Stack

- Transformers â€“ for model pipelines  
- PyTorch â€“ as backend for transformer models  
- Scikit-learn â€“ for cosine similarity  
- NLTK â€“ for sentence tokenization  
- NumPy â€“ for vector operations  
- Sentence-Transformers â€“ for MiniLM-based embeddings  

---

## ğŸ§ª Model Details

### ğŸ”¹ Abstractive Summarization

The abstractive model used is `facebook/bart-large-cnn`, which leverages natural language generation to create fluent and semantically rich summaries that do not simply extract from the original text but rather generate a new version conveying the same meaning.

### ğŸ”¸ Extractive Summarization

The extractive summarizer uses `sentence-transformers/all-MiniLM-L6-v2` to embed sentences and then selects the most relevant ones using cosine similarity. It performs well on short to medium-length inputs.  
**Note:** On longer text documents, extractive summarization may fail due to **index out-of-range** issues caused by transformer input size limitations.

---

## ğŸ“Œ Use Cases

- ğŸ“° News summarization  
- ğŸ“š Academic research briefs  
- ğŸ“„ Legal document summarization  
- ğŸ“± Content previews in applications  
- âœï¸ Assisting content creators with concise drafts  

---

## ğŸ’¡ Future Enhancements

- âœ… Add support for long document chunking in extractive summarization  
- ğŸš€ Integrate a Streamlit interface for user-friendly interaction  
- ğŸ§  Introduce fine-tuned models for domain-specific summarization (e.g., healthcare, finance)  
- ğŸ“Š Add evaluation metrics (e.g., ROUGE, BLEU)    

